{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8948c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ec465c",
   "metadata": {},
   "source": [
    "# 张量初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fceb2a5",
   "metadata": {},
   "source": [
    "## 1.直接生成张量\n",
    "### 由原始数据直接生成张量, 张量类型由原始数据类型决定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "681e0853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5c1690",
   "metadata": {},
   "source": [
    "## 2.通过Numpy数组来生成张量\n",
    "### 由已有的Numpy数组来生成张量(反过来也可以由张量来生成Numpy数组, 参考张量与Numpy之间的转换)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "076f3620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e9bf0",
   "metadata": {},
   "source": [
    "## 3.通过已有的张量来生成新的张量\n",
    "### 新的张量将继承已有张量的数据属性(结构、类型), 也可以重新指定新的数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eac068b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # 保留x_data的属性\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5cf35d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.9631, 0.3030],\n",
      "        [0.2117, 0.0182]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_rand = torch.rand_like(x_data, dtype = torch.float) # 重写 x_data 的数据类型(int -> float)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa4647",
   "metadata": {},
   "source": [
    "##  4. 通过指定数据维度来生成张量\n",
    "### shape是元组类型, 用来描述张量的维数, 下面3个函数通过传入shape来指定生成张量的维数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "435fab42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.5978, 0.7626, 0.5112],\n",
      "        [0.4333, 0.4866, 0.1804]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3, )\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ca3ba",
   "metadata": {},
   "source": [
    "# 张量属性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edefdf9",
   "metadata": {},
   "source": [
    "## 从张量属性我们可以得到张量的维数、数据类型以及它们所存储的设备(CPU或GPU)。\n",
    "### 来看一个简单的例子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4595d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea96604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of tensor: torch.Size([3, 4])   # 维数\n",
    "# Datatype of tensor: torch.float32     # 数据类型\n",
    "# Device tensor is stored on: cpu       # 存储设备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23048cc1",
   "metadata": {},
   "source": [
    "# 张量运算 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a299dfa7",
   "metadata": {},
   "source": [
    "### 有超过100种张量相关的运算操作, 例如转置、索引、切片、数学运算、线性代数、随机采样等。更多的运算可以在这里查看。\n",
    "### 所有这些运算都可以在GPU上运行(相对于CPU来说可以达到更高的运算速度)。如果你使用的是Google的Colab环境, 可以通过 Edit > Notebook Settings 来分配一个GPU使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e7f9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判断当前环境GPU是否可用, 然后将tensor导入GPU内运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b5f7517",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e291e0f6",
   "metadata": {},
   "source": [
    "## 1.张量的索引和切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aefe9db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0            # 将第1列(从0开始)的数据全部赋值为0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338527f0",
   "metadata": {},
   "source": [
    "## 2.张量的拼接 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0622b9",
   "metadata": {},
   "source": [
    "###  你可以通过torch.cat方法将一组张量按照指定的维度进行拼接, 也可以参考torch.stack方法。这个方法也可以实现拼接操作, 但和torch.cat稍微有点不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23fdc897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim = 1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db0958d",
   "metadata": {},
   "source": [
    "## 3.张量的乘积和矩阵乘法 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aaa98fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.mul(tensor): \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor * tensor: \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 逐个元素相乘结果\n",
    "print(f\"tensor.mul(tensor): \\n {tensor.mul(tensor)} \\n\")\n",
    "# 等价写法:\n",
    "print(f\"tensor * tensor: \\n {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33b19564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面写法表示张量与张量的矩阵乘法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25f42bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor.T): \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "tensor @ tensor.T: \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensor.matmul(tensor.T): \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# 等价写法:\n",
    "print(f\"tensor @ tensor.T: \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bb47a",
   "metadata": {},
   "source": [
    "## 4.自动赋值计算 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c812f",
   "metadata": {},
   "source": [
    "###  自动赋值运算通常在方法后有 _ 作为后缀, 例如: x.copy_(y), x.t_()操作会改变 x 的取值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb04c3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed3be2",
   "metadata": {},
   "source": [
    "> 注意\n",
    ">\n",
    "> 自动赋值运算虽然可以节省内存, 但在求导时会因为丢失了中间过程而导致一些问题, 所以我们并不鼓励使用它。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b104859",
   "metadata": {},
   "source": [
    "# 5. Tensor与Numpy的转化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835f8914",
   "metadata": {},
   "source": [
    "> 张量和Numpy array数组在CPU上可以共用一块内存区域, 改变其中一个另一个也会随之改变。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc43db10",
   "metadata": {},
   "source": [
    "## 1. 由张量变换为Numpy array数组 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e3a6cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccb7b26",
   "metadata": {},
   "source": [
    "###  修改张量的值，则Numpy array数组值也会随之改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a226a92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc357b28",
   "metadata": {},
   "source": [
    "## 2. 由Numpy array数组转为张量 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3341cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335c3d3f",
   "metadata": {},
   "source": [
    "### 修改Numpy array数组的值，则张量值也会随之改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4aee209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
